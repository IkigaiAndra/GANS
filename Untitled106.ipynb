{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKucSlyvJGh7",
        "outputId": "f68bfe97-e480-4192-bd67-ce706303e1b2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 16.7MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 276kB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.00MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Epoch [0/50], Step [0/938], Loss D: 1.3956, Loss G: 0.6740\n",
            "Epoch [0/50], Step [100/938], Loss D: 0.6090, Loss G: 1.3286\n",
            "Epoch [0/50], Step [200/938], Loss D: 0.4601, Loss G: 2.5100\n",
            "Epoch [0/50], Step [300/938], Loss D: 0.5475, Loss G: 2.9061\n",
            "Epoch [0/50], Step [400/938], Loss D: 0.5370, Loss G: 2.2823\n",
            "Epoch [0/50], Step [500/938], Loss D: 0.7484, Loss G: 1.7488\n",
            "Epoch [0/50], Step [600/938], Loss D: 0.9578, Loss G: 2.5706\n",
            "Epoch [0/50], Step [700/938], Loss D: 0.9184, Loss G: 2.0503\n",
            "Epoch [0/50], Step [800/938], Loss D: 0.5534, Loss G: 2.4223\n",
            "Epoch [0/50], Step [900/938], Loss D: 1.0371, Loss G: 2.6712\n",
            "Epoch [1/50], Step [0/938], Loss D: 0.8086, Loss G: 2.4999\n",
            "Epoch [1/50], Step [100/938], Loss D: 0.7907, Loss G: 3.2434\n",
            "Epoch [1/50], Step [200/938], Loss D: 0.9964, Loss G: 2.4417\n",
            "Epoch [1/50], Step [300/938], Loss D: 0.8588, Loss G: 1.2442\n",
            "Epoch [1/50], Step [400/938], Loss D: 1.1314, Loss G: 2.2527\n",
            "Epoch [1/50], Step [500/938], Loss D: 1.0374, Loss G: 1.3086\n",
            "Epoch [1/50], Step [600/938], Loss D: 0.9027, Loss G: 1.2889\n",
            "Epoch [1/50], Step [700/938], Loss D: 1.0399, Loss G: 1.9583\n",
            "Epoch [1/50], Step [800/938], Loss D: 1.1960, Loss G: 1.6491\n",
            "Epoch [1/50], Step [900/938], Loss D: 1.1468, Loss G: 1.2761\n",
            "Epoch [2/50], Step [0/938], Loss D: 1.1754, Loss G: 1.4466\n",
            "Epoch [2/50], Step [100/938], Loss D: 1.1614, Loss G: 1.0428\n",
            "Epoch [2/50], Step [200/938], Loss D: 1.2055, Loss G: 1.7026\n",
            "Epoch [2/50], Step [300/938], Loss D: 1.3141, Loss G: 1.0348\n",
            "Epoch [2/50], Step [400/938], Loss D: 1.1868, Loss G: 1.7255\n",
            "Epoch [2/50], Step [500/938], Loss D: 1.0738, Loss G: 1.2226\n",
            "Epoch [2/50], Step [600/938], Loss D: 1.1072, Loss G: 1.0563\n",
            "Epoch [2/50], Step [700/938], Loss D: 1.0646, Loss G: 1.3811\n",
            "Epoch [2/50], Step [800/938], Loss D: 1.0924, Loss G: 1.0614\n",
            "Epoch [2/50], Step [900/938], Loss D: 1.1053, Loss G: 1.1696\n",
            "Epoch [3/50], Step [0/938], Loss D: 1.1159, Loss G: 1.1038\n",
            "Epoch [3/50], Step [100/938], Loss D: 1.2680, Loss G: 1.2266\n",
            "Epoch [3/50], Step [200/938], Loss D: 1.0309, Loss G: 1.4735\n",
            "Epoch [3/50], Step [300/938], Loss D: 1.1432, Loss G: 1.2095\n",
            "Epoch [3/50], Step [400/938], Loss D: 1.1047, Loss G: 1.4761\n",
            "Epoch [3/50], Step [500/938], Loss D: 1.1751, Loss G: 0.9834\n",
            "Epoch [3/50], Step [600/938], Loss D: 1.2296, Loss G: 1.4113\n",
            "Epoch [3/50], Step [700/938], Loss D: 1.0432, Loss G: 1.1880\n",
            "Epoch [3/50], Step [800/938], Loss D: 1.3247, Loss G: 0.9943\n",
            "Epoch [3/50], Step [900/938], Loss D: 1.1735, Loss G: 1.1224\n",
            "Epoch [4/50], Step [0/938], Loss D: 1.1207, Loss G: 1.4305\n",
            "Epoch [4/50], Step [100/938], Loss D: 1.2040, Loss G: 1.4446\n",
            "Epoch [4/50], Step [200/938], Loss D: 1.2437, Loss G: 0.9275\n",
            "Epoch [4/50], Step [300/938], Loss D: 1.1317, Loss G: 1.1713\n",
            "Epoch [4/50], Step [400/938], Loss D: 1.2687, Loss G: 0.8685\n",
            "Epoch [4/50], Step [500/938], Loss D: 1.2828, Loss G: 0.9389\n",
            "Epoch [4/50], Step [600/938], Loss D: 1.2682, Loss G: 0.9305\n",
            "Epoch [4/50], Step [700/938], Loss D: 1.2342, Loss G: 0.9115\n",
            "Epoch [4/50], Step [800/938], Loss D: 1.2847, Loss G: 0.8860\n",
            "Epoch [4/50], Step [900/938], Loss D: 1.2026, Loss G: 1.4192\n",
            "Epoch [5/50], Step [0/938], Loss D: 1.1863, Loss G: 1.8948\n",
            "Epoch [5/50], Step [100/938], Loss D: 1.1842, Loss G: 0.9722\n",
            "Epoch [5/50], Step [200/938], Loss D: 1.2525, Loss G: 1.1697\n",
            "Epoch [5/50], Step [300/938], Loss D: 1.2358, Loss G: 0.9527\n",
            "Epoch [5/50], Step [400/938], Loss D: 1.2961, Loss G: 1.1392\n",
            "Epoch [5/50], Step [500/938], Loss D: 1.2695, Loss G: 0.9271\n",
            "Epoch [5/50], Step [600/938], Loss D: 1.2467, Loss G: 0.8532\n",
            "Epoch [5/50], Step [700/938], Loss D: 1.3286, Loss G: 1.2240\n",
            "Epoch [5/50], Step [800/938], Loss D: 1.1554, Loss G: 1.0390\n",
            "Epoch [5/50], Step [900/938], Loss D: 1.2595, Loss G: 0.9654\n",
            "Epoch [6/50], Step [0/938], Loss D: 1.3048, Loss G: 0.9934\n",
            "Epoch [6/50], Step [100/938], Loss D: 1.3231, Loss G: 1.2425\n",
            "Epoch [6/50], Step [200/938], Loss D: 1.2177, Loss G: 0.9780\n",
            "Epoch [6/50], Step [300/938], Loss D: 1.2601, Loss G: 1.0621\n",
            "Epoch [6/50], Step [400/938], Loss D: 1.3467, Loss G: 0.9899\n",
            "Epoch [6/50], Step [500/938], Loss D: 1.2946, Loss G: 1.0035\n",
            "Epoch [6/50], Step [600/938], Loss D: 1.3681, Loss G: 0.9579\n",
            "Epoch [6/50], Step [700/938], Loss D: 1.2487, Loss G: 1.0693\n",
            "Epoch [6/50], Step [800/938], Loss D: 1.2617, Loss G: 0.8996\n",
            "Epoch [6/50], Step [900/938], Loss D: 1.3703, Loss G: 0.8858\n",
            "Epoch [7/50], Step [0/938], Loss D: 1.3479, Loss G: 1.2470\n",
            "Epoch [7/50], Step [100/938], Loss D: 1.3204, Loss G: 0.8476\n",
            "Epoch [7/50], Step [200/938], Loss D: 1.3886, Loss G: 1.1896\n",
            "Epoch [7/50], Step [300/938], Loss D: 1.2970, Loss G: 0.8095\n",
            "Epoch [7/50], Step [400/938], Loss D: 1.2988, Loss G: 0.8102\n",
            "Epoch [7/50], Step [500/938], Loss D: 1.2894, Loss G: 0.8683\n",
            "Epoch [7/50], Step [600/938], Loss D: 1.2832, Loss G: 1.0759\n",
            "Epoch [7/50], Step [700/938], Loss D: 1.1615, Loss G: 1.0560\n",
            "Epoch [7/50], Step [800/938], Loss D: 1.3604, Loss G: 0.7951\n",
            "Epoch [7/50], Step [900/938], Loss D: 1.2702, Loss G: 0.9117\n",
            "Epoch [8/50], Step [0/938], Loss D: 1.3085, Loss G: 0.8718\n",
            "Epoch [8/50], Step [100/938], Loss D: 1.3478, Loss G: 1.0419\n",
            "Epoch [8/50], Step [200/938], Loss D: 1.2656, Loss G: 0.8832\n",
            "Epoch [8/50], Step [300/938], Loss D: 1.2843, Loss G: 0.8678\n",
            "Epoch [8/50], Step [400/938], Loss D: 1.2404, Loss G: 0.9730\n",
            "Epoch [8/50], Step [500/938], Loss D: 1.3096, Loss G: 0.9436\n",
            "Epoch [8/50], Step [600/938], Loss D: 1.3382, Loss G: 0.8939\n",
            "Epoch [8/50], Step [700/938], Loss D: 1.2634, Loss G: 1.2303\n",
            "Epoch [8/50], Step [800/938], Loss D: 1.3193, Loss G: 0.8772\n",
            "Epoch [8/50], Step [900/938], Loss D: 1.3061, Loss G: 0.9537\n",
            "Epoch [9/50], Step [0/938], Loss D: 1.2897, Loss G: 1.0665\n",
            "Epoch [9/50], Step [100/938], Loss D: 1.3159, Loss G: 0.8361\n",
            "Epoch [9/50], Step [200/938], Loss D: 1.3939, Loss G: 0.7558\n",
            "Epoch [9/50], Step [300/938], Loss D: 1.3202, Loss G: 0.8160\n",
            "Epoch [9/50], Step [400/938], Loss D: 1.2436, Loss G: 0.8516\n",
            "Epoch [9/50], Step [500/938], Loss D: 1.2545, Loss G: 0.9627\n",
            "Epoch [9/50], Step [600/938], Loss D: 1.3469, Loss G: 0.9862\n",
            "Epoch [9/50], Step [700/938], Loss D: 1.3769, Loss G: 0.8798\n",
            "Epoch [9/50], Step [800/938], Loss D: 1.3536, Loss G: 1.0181\n",
            "Epoch [9/50], Step [900/938], Loss D: 1.3207, Loss G: 0.7330\n",
            "Epoch [10/50], Step [0/938], Loss D: 1.3343, Loss G: 0.9288\n",
            "Epoch [10/50], Step [100/938], Loss D: 1.3167, Loss G: 0.9486\n",
            "Epoch [10/50], Step [200/938], Loss D: 1.2917, Loss G: 0.9960\n",
            "Epoch [10/50], Step [300/938], Loss D: 1.3186, Loss G: 0.7138\n",
            "Epoch [10/50], Step [400/938], Loss D: 1.3314, Loss G: 0.9264\n",
            "Epoch [10/50], Step [500/938], Loss D: 1.2072, Loss G: 1.0029\n",
            "Epoch [10/50], Step [600/938], Loss D: 1.2865, Loss G: 1.0998\n",
            "Epoch [10/50], Step [700/938], Loss D: 1.3059, Loss G: 0.9606\n",
            "Epoch [10/50], Step [800/938], Loss D: 1.3346, Loss G: 1.0454\n",
            "Epoch [10/50], Step [900/938], Loss D: 1.2524, Loss G: 1.0585\n",
            "Epoch [11/50], Step [0/938], Loss D: 1.3274, Loss G: 0.8146\n",
            "Epoch [11/50], Step [100/938], Loss D: 1.2982, Loss G: 0.9094\n",
            "Epoch [11/50], Step [200/938], Loss D: 1.3182, Loss G: 0.8508\n",
            "Epoch [11/50], Step [300/938], Loss D: 1.2909, Loss G: 0.9674\n",
            "Epoch [11/50], Step [400/938], Loss D: 1.2398, Loss G: 1.0303\n",
            "Epoch [11/50], Step [500/938], Loss D: 1.3189, Loss G: 0.9912\n",
            "Epoch [11/50], Step [600/938], Loss D: 1.3578, Loss G: 0.7572\n",
            "Epoch [11/50], Step [700/938], Loss D: 1.3726, Loss G: 0.8355\n",
            "Epoch [11/50], Step [800/938], Loss D: 1.2807, Loss G: 0.9728\n",
            "Epoch [11/50], Step [900/938], Loss D: 1.2144, Loss G: 1.0569\n",
            "Epoch [12/50], Step [0/938], Loss D: 1.3552, Loss G: 0.8507\n",
            "Epoch [12/50], Step [100/938], Loss D: 1.3546, Loss G: 0.7878\n",
            "Epoch [12/50], Step [200/938], Loss D: 1.2625, Loss G: 0.9050\n",
            "Epoch [12/50], Step [300/938], Loss D: 1.3667, Loss G: 0.9050\n",
            "Epoch [12/50], Step [400/938], Loss D: 1.3500, Loss G: 1.0517\n",
            "Epoch [12/50], Step [500/938], Loss D: 1.3203, Loss G: 0.8447\n",
            "Epoch [12/50], Step [600/938], Loss D: 1.3420, Loss G: 0.8671\n",
            "Epoch [12/50], Step [700/938], Loss D: 1.2521, Loss G: 1.0325\n",
            "Epoch [12/50], Step [800/938], Loss D: 1.2601, Loss G: 1.1272\n",
            "Epoch [12/50], Step [900/938], Loss D: 1.3332, Loss G: 0.9750\n",
            "Epoch [13/50], Step [0/938], Loss D: 1.3387, Loss G: 1.3403\n",
            "Epoch [13/50], Step [100/938], Loss D: 1.2874, Loss G: 0.8037\n",
            "Epoch [13/50], Step [200/938], Loss D: 1.2666, Loss G: 0.9481\n",
            "Epoch [13/50], Step [300/938], Loss D: 1.3719, Loss G: 1.1470\n",
            "Epoch [13/50], Step [400/938], Loss D: 1.3100, Loss G: 1.0857\n",
            "Epoch [13/50], Step [500/938], Loss D: 1.2898, Loss G: 0.9433\n",
            "Epoch [13/50], Step [600/938], Loss D: 1.2563, Loss G: 1.0679\n",
            "Epoch [13/50], Step [700/938], Loss D: 1.3272, Loss G: 0.9296\n",
            "Epoch [13/50], Step [800/938], Loss D: 1.3028, Loss G: 0.8530\n",
            "Epoch [13/50], Step [900/938], Loss D: 1.2703, Loss G: 0.9763\n",
            "Epoch [14/50], Step [0/938], Loss D: 1.3075, Loss G: 0.9398\n",
            "Epoch [14/50], Step [100/938], Loss D: 1.2943, Loss G: 0.8980\n",
            "Epoch [14/50], Step [200/938], Loss D: 1.3525, Loss G: 0.7748\n",
            "Epoch [14/50], Step [300/938], Loss D: 1.3338, Loss G: 0.9878\n",
            "Epoch [14/50], Step [400/938], Loss D: 1.3291, Loss G: 0.8530\n",
            "Epoch [14/50], Step [500/938], Loss D: 1.3324, Loss G: 0.8729\n",
            "Epoch [14/50], Step [600/938], Loss D: 1.2842, Loss G: 0.9840\n",
            "Epoch [14/50], Step [700/938], Loss D: 1.3447, Loss G: 0.8946\n",
            "Epoch [14/50], Step [800/938], Loss D: 1.2934, Loss G: 0.8392\n",
            "Epoch [14/50], Step [900/938], Loss D: 1.3763, Loss G: 0.7438\n",
            "Epoch [15/50], Step [0/938], Loss D: 1.2811, Loss G: 0.8473\n",
            "Epoch [15/50], Step [100/938], Loss D: 1.3151, Loss G: 0.7970\n",
            "Epoch [15/50], Step [200/938], Loss D: 1.2682, Loss G: 0.8586\n",
            "Epoch [15/50], Step [300/938], Loss D: 1.2899, Loss G: 0.9073\n",
            "Epoch [15/50], Step [400/938], Loss D: 1.3250, Loss G: 0.8950\n",
            "Epoch [15/50], Step [500/938], Loss D: 1.3617, Loss G: 0.8579\n",
            "Epoch [15/50], Step [600/938], Loss D: 1.2839, Loss G: 0.9742\n",
            "Epoch [15/50], Step [700/938], Loss D: 1.4134, Loss G: 0.8615\n",
            "Epoch [15/50], Step [800/938], Loss D: 1.3358, Loss G: 0.9080\n",
            "Epoch [15/50], Step [900/938], Loss D: 1.3050, Loss G: 0.7839\n",
            "Epoch [16/50], Step [0/938], Loss D: 1.3763, Loss G: 0.9594\n",
            "Epoch [16/50], Step [100/938], Loss D: 1.3209, Loss G: 0.8791\n",
            "Epoch [16/50], Step [200/938], Loss D: 1.4241, Loss G: 0.7269\n",
            "Epoch [16/50], Step [300/938], Loss D: 1.3654, Loss G: 0.8410\n",
            "Epoch [16/50], Step [400/938], Loss D: 1.4014, Loss G: 0.7970\n",
            "Epoch [16/50], Step [500/938], Loss D: 1.3435, Loss G: 0.7101\n",
            "Epoch [16/50], Step [600/938], Loss D: 1.3353, Loss G: 0.8481\n",
            "Epoch [16/50], Step [700/938], Loss D: 1.3649, Loss G: 0.7251\n",
            "Epoch [16/50], Step [800/938], Loss D: 1.3147, Loss G: 0.7282\n",
            "Epoch [16/50], Step [900/938], Loss D: 1.3630, Loss G: 0.8284\n",
            "Epoch [17/50], Step [0/938], Loss D: 1.3555, Loss G: 0.8478\n",
            "Epoch [17/50], Step [100/938], Loss D: 1.3639, Loss G: 0.7783\n",
            "Epoch [17/50], Step [200/938], Loss D: 1.3301, Loss G: 0.8477\n",
            "Epoch [17/50], Step [300/938], Loss D: 1.3981, Loss G: 0.7933\n",
            "Epoch [17/50], Step [400/938], Loss D: 1.3776, Loss G: 0.8501\n",
            "Epoch [17/50], Step [500/938], Loss D: 1.3099, Loss G: 0.8400\n",
            "Epoch [17/50], Step [600/938], Loss D: 1.3632, Loss G: 0.7825\n",
            "Epoch [17/50], Step [700/938], Loss D: 1.3513, Loss G: 0.8619\n",
            "Epoch [17/50], Step [800/938], Loss D: 1.4477, Loss G: 0.8641\n",
            "Epoch [17/50], Step [900/938], Loss D: 1.2973, Loss G: 0.9066\n",
            "Epoch [18/50], Step [0/938], Loss D: 1.4818, Loss G: 0.8602\n",
            "Epoch [18/50], Step [100/938], Loss D: 1.3417, Loss G: 0.8122\n",
            "Epoch [18/50], Step [200/938], Loss D: 1.3548, Loss G: 0.9164\n",
            "Epoch [18/50], Step [300/938], Loss D: 1.3371, Loss G: 0.8261\n",
            "Epoch [18/50], Step [400/938], Loss D: 1.3954, Loss G: 0.8254\n",
            "Epoch [18/50], Step [500/938], Loss D: 1.2819, Loss G: 0.9013\n",
            "Epoch [18/50], Step [600/938], Loss D: 1.3532, Loss G: 0.7603\n",
            "Epoch [18/50], Step [700/938], Loss D: 1.4660, Loss G: 0.7426\n",
            "Epoch [18/50], Step [800/938], Loss D: 1.2872, Loss G: 0.8641\n",
            "Epoch [18/50], Step [900/938], Loss D: 1.4044, Loss G: 0.7966\n",
            "Epoch [19/50], Step [0/938], Loss D: 1.3891, Loss G: 0.7439\n",
            "Epoch [19/50], Step [100/938], Loss D: 1.3213, Loss G: 0.8693\n",
            "Epoch [19/50], Step [200/938], Loss D: 1.3174, Loss G: 0.8855\n",
            "Epoch [19/50], Step [300/938], Loss D: 1.3149, Loss G: 1.0435\n",
            "Epoch [19/50], Step [400/938], Loss D: 1.3078, Loss G: 0.9109\n",
            "Epoch [19/50], Step [500/938], Loss D: 1.3250, Loss G: 0.8902\n",
            "Epoch [19/50], Step [600/938], Loss D: 1.3224, Loss G: 0.8569\n",
            "Epoch [19/50], Step [700/938], Loss D: 1.3828, Loss G: 0.8739\n",
            "Epoch [19/50], Step [800/938], Loss D: 1.3058, Loss G: 0.7859\n",
            "Epoch [19/50], Step [900/938], Loss D: 1.3460, Loss G: 0.8126\n",
            "Epoch [20/50], Step [0/938], Loss D: 1.3155, Loss G: 0.8368\n",
            "Epoch [20/50], Step [100/938], Loss D: 1.3587, Loss G: 0.8845\n",
            "Epoch [20/50], Step [200/938], Loss D: 1.3712, Loss G: 0.8268\n",
            "Epoch [20/50], Step [300/938], Loss D: 1.2822, Loss G: 0.8015\n",
            "Epoch [20/50], Step [400/938], Loss D: 1.3553, Loss G: 0.8094\n",
            "Epoch [20/50], Step [500/938], Loss D: 1.3170, Loss G: 0.8259\n",
            "Epoch [20/50], Step [600/938], Loss D: 1.3579, Loss G: 0.8635\n",
            "Epoch [20/50], Step [700/938], Loss D: 1.3173, Loss G: 0.8670\n",
            "Epoch [20/50], Step [800/938], Loss D: 1.3098, Loss G: 0.8601\n",
            "Epoch [20/50], Step [900/938], Loss D: 1.3663, Loss G: 0.8195\n",
            "Epoch [21/50], Step [0/938], Loss D: 1.3370, Loss G: 0.8173\n",
            "Epoch [21/50], Step [100/938], Loss D: 1.3324, Loss G: 0.9339\n",
            "Epoch [21/50], Step [200/938], Loss D: 1.3365, Loss G: 0.9630\n",
            "Epoch [21/50], Step [300/938], Loss D: 1.2826, Loss G: 0.8746\n",
            "Epoch [21/50], Step [400/938], Loss D: 1.3139, Loss G: 0.8350\n",
            "Epoch [21/50], Step [500/938], Loss D: 1.3207, Loss G: 0.9208\n",
            "Epoch [21/50], Step [600/938], Loss D: 1.3435, Loss G: 0.8134\n",
            "Epoch [21/50], Step [700/938], Loss D: 1.3107, Loss G: 0.8217\n",
            "Epoch [21/50], Step [800/938], Loss D: 1.2796, Loss G: 0.8578\n",
            "Epoch [21/50], Step [900/938], Loss D: 1.3528, Loss G: 0.7642\n",
            "Epoch [22/50], Step [0/938], Loss D: 1.3527, Loss G: 0.8035\n",
            "Epoch [22/50], Step [100/938], Loss D: 1.3386, Loss G: 0.7976\n",
            "Epoch [22/50], Step [200/938], Loss D: 1.2855, Loss G: 0.8538\n",
            "Epoch [22/50], Step [300/938], Loss D: 1.3518, Loss G: 0.8296\n",
            "Epoch [22/50], Step [400/938], Loss D: 1.4475, Loss G: 0.8432\n",
            "Epoch [22/50], Step [500/938], Loss D: 1.3173, Loss G: 0.8465\n",
            "Epoch [22/50], Step [600/938], Loss D: 1.3526, Loss G: 0.8967\n",
            "Epoch [22/50], Step [700/938], Loss D: 1.4251, Loss G: 0.8045\n",
            "Epoch [22/50], Step [800/938], Loss D: 1.3545, Loss G: 0.9147\n",
            "Epoch [22/50], Step [900/938], Loss D: 1.3041, Loss G: 0.8389\n",
            "Epoch [23/50], Step [0/938], Loss D: 1.2824, Loss G: 0.8460\n",
            "Epoch [23/50], Step [100/938], Loss D: 1.3923, Loss G: 0.8224\n",
            "Epoch [23/50], Step [200/938], Loss D: 1.3952, Loss G: 0.7472\n",
            "Epoch [23/50], Step [300/938], Loss D: 1.3149, Loss G: 0.8238\n",
            "Epoch [23/50], Step [400/938], Loss D: 1.3275, Loss G: 0.8856\n",
            "Epoch [23/50], Step [500/938], Loss D: 1.3429, Loss G: 0.8862\n",
            "Epoch [23/50], Step [600/938], Loss D: 1.3166, Loss G: 0.8016\n",
            "Epoch [23/50], Step [700/938], Loss D: 1.3752, Loss G: 0.8005\n",
            "Epoch [23/50], Step [800/938], Loss D: 1.3265, Loss G: 0.8043\n",
            "Epoch [23/50], Step [900/938], Loss D: 1.2655, Loss G: 0.9159\n",
            "Epoch [24/50], Step [0/938], Loss D: 1.2968, Loss G: 0.8904\n",
            "Epoch [24/50], Step [100/938], Loss D: 1.2926, Loss G: 0.8400\n",
            "Epoch [24/50], Step [200/938], Loss D: 1.3907, Loss G: 0.7512\n",
            "Epoch [24/50], Step [300/938], Loss D: 1.2662, Loss G: 0.8838\n",
            "Epoch [24/50], Step [400/938], Loss D: 1.3745, Loss G: 0.8778\n",
            "Epoch [24/50], Step [500/938], Loss D: 1.2979, Loss G: 0.8780\n",
            "Epoch [24/50], Step [600/938], Loss D: 1.3580, Loss G: 0.8536\n",
            "Epoch [24/50], Step [700/938], Loss D: 1.3576, Loss G: 0.8101\n",
            "Epoch [24/50], Step [800/938], Loss D: 1.3264, Loss G: 0.8683\n",
            "Epoch [24/50], Step [900/938], Loss D: 1.3713, Loss G: 0.8178\n",
            "Epoch [25/50], Step [0/938], Loss D: 1.3611, Loss G: 0.8542\n",
            "Epoch [25/50], Step [100/938], Loss D: 1.3359, Loss G: 0.8716\n",
            "Epoch [25/50], Step [200/938], Loss D: 1.3663, Loss G: 0.8502\n",
            "Epoch [25/50], Step [300/938], Loss D: 1.2747, Loss G: 0.8630\n",
            "Epoch [25/50], Step [400/938], Loss D: 1.3201, Loss G: 0.8280\n",
            "Epoch [25/50], Step [500/938], Loss D: 1.3345, Loss G: 0.8492\n",
            "Epoch [25/50], Step [600/938], Loss D: 1.3540, Loss G: 0.8276\n",
            "Epoch [25/50], Step [700/938], Loss D: 1.3231, Loss G: 0.8215\n",
            "Epoch [25/50], Step [800/938], Loss D: 1.3237, Loss G: 0.8490\n",
            "Epoch [25/50], Step [900/938], Loss D: 1.2490, Loss G: 0.8892\n",
            "Epoch [26/50], Step [0/938], Loss D: 1.3189, Loss G: 0.8903\n",
            "Epoch [26/50], Step [100/938], Loss D: 1.3517, Loss G: 0.8192\n",
            "Epoch [26/50], Step [200/938], Loss D: 1.3045, Loss G: 0.9246\n",
            "Epoch [26/50], Step [300/938], Loss D: 1.3325, Loss G: 0.8795\n",
            "Epoch [26/50], Step [400/938], Loss D: 1.2922, Loss G: 0.9352\n",
            "Epoch [26/50], Step [500/938], Loss D: 1.3614, Loss G: 0.7895\n",
            "Epoch [26/50], Step [600/938], Loss D: 1.3036, Loss G: 0.8728\n",
            "Epoch [26/50], Step [700/938], Loss D: 1.3326, Loss G: 0.7915\n",
            "Epoch [26/50], Step [800/938], Loss D: 1.3806, Loss G: 0.8482\n",
            "Epoch [26/50], Step [900/938], Loss D: 1.3257, Loss G: 0.8206\n",
            "Epoch [27/50], Step [0/938], Loss D: 1.2816, Loss G: 0.9041\n",
            "Epoch [27/50], Step [100/938], Loss D: 1.3776, Loss G: 0.8365\n",
            "Epoch [27/50], Step [200/938], Loss D: 1.3217, Loss G: 0.8262\n",
            "Epoch [27/50], Step [300/938], Loss D: 1.3400, Loss G: 0.8199\n",
            "Epoch [27/50], Step [400/938], Loss D: 1.4058, Loss G: 0.8065\n",
            "Epoch [27/50], Step [500/938], Loss D: 1.3307, Loss G: 0.8297\n",
            "Epoch [27/50], Step [600/938], Loss D: 1.3360, Loss G: 0.8095\n",
            "Epoch [27/50], Step [700/938], Loss D: 1.3261, Loss G: 0.8063\n",
            "Epoch [27/50], Step [800/938], Loss D: 1.3843, Loss G: 0.8407\n",
            "Epoch [27/50], Step [900/938], Loss D: 1.3410, Loss G: 0.8487\n",
            "Epoch [28/50], Step [0/938], Loss D: 1.3401, Loss G: 0.7806\n",
            "Epoch [28/50], Step [100/938], Loss D: 1.3798, Loss G: 0.8003\n",
            "Epoch [28/50], Step [200/938], Loss D: 1.3401, Loss G: 0.8102\n",
            "Epoch [28/50], Step [300/938], Loss D: 1.4536, Loss G: 0.8318\n",
            "Epoch [28/50], Step [400/938], Loss D: 1.3132, Loss G: 0.9034\n",
            "Epoch [28/50], Step [500/938], Loss D: 1.3943, Loss G: 0.8149\n",
            "Epoch [28/50], Step [600/938], Loss D: 1.3296, Loss G: 0.8414\n",
            "Epoch [28/50], Step [700/938], Loss D: 1.3643, Loss G: 0.8013\n",
            "Epoch [28/50], Step [800/938], Loss D: 1.3553, Loss G: 0.8228\n",
            "Epoch [28/50], Step [900/938], Loss D: 1.3570, Loss G: 0.8696\n",
            "Epoch [29/50], Step [0/938], Loss D: 1.3935, Loss G: 0.8074\n",
            "Epoch [29/50], Step [100/938], Loss D: 1.3260, Loss G: 0.8225\n",
            "Epoch [29/50], Step [200/938], Loss D: 1.2915, Loss G: 0.8348\n",
            "Epoch [29/50], Step [300/938], Loss D: 1.3075, Loss G: 0.8320\n",
            "Epoch [29/50], Step [400/938], Loss D: 1.3438, Loss G: 0.8625\n",
            "Epoch [29/50], Step [500/938], Loss D: 1.3702, Loss G: 0.7734\n",
            "Epoch [29/50], Step [600/938], Loss D: 1.3864, Loss G: 0.8882\n",
            "Epoch [29/50], Step [700/938], Loss D: 1.3516, Loss G: 0.8665\n",
            "Epoch [29/50], Step [800/938], Loss D: 1.2717, Loss G: 0.8344\n",
            "Epoch [29/50], Step [900/938], Loss D: 1.3055, Loss G: 0.8419\n",
            "Epoch [30/50], Step [0/938], Loss D: 1.3690, Loss G: 0.8658\n",
            "Epoch [30/50], Step [100/938], Loss D: 1.3033, Loss G: 0.8303\n",
            "Epoch [30/50], Step [200/938], Loss D: 1.2816, Loss G: 0.8297\n",
            "Epoch [30/50], Step [300/938], Loss D: 1.3186, Loss G: 0.8673\n",
            "Epoch [30/50], Step [400/938], Loss D: 1.3568, Loss G: 0.8511\n",
            "Epoch [30/50], Step [500/938], Loss D: 1.3965, Loss G: 0.8149\n",
            "Epoch [30/50], Step [600/938], Loss D: 1.3386, Loss G: 0.8257\n",
            "Epoch [30/50], Step [700/938], Loss D: 1.3453, Loss G: 0.7805\n",
            "Epoch [30/50], Step [800/938], Loss D: 1.3709, Loss G: 0.7821\n",
            "Epoch [30/50], Step [900/938], Loss D: 1.3792, Loss G: 0.7773\n",
            "Epoch [31/50], Step [0/938], Loss D: 1.3687, Loss G: 0.8184\n",
            "Epoch [31/50], Step [100/938], Loss D: 1.2952, Loss G: 0.8649\n",
            "Epoch [31/50], Step [200/938], Loss D: 1.3104, Loss G: 0.8541\n",
            "Epoch [31/50], Step [300/938], Loss D: 1.2921, Loss G: 0.8392\n",
            "Epoch [31/50], Step [400/938], Loss D: 1.3574, Loss G: 0.8349\n",
            "Epoch [31/50], Step [500/938], Loss D: 1.3588, Loss G: 0.7947\n",
            "Epoch [31/50], Step [600/938], Loss D: 1.3429, Loss G: 0.8481\n",
            "Epoch [31/50], Step [700/938], Loss D: 1.3429, Loss G: 0.7700\n",
            "Epoch [31/50], Step [800/938], Loss D: 1.3055, Loss G: 0.8503\n",
            "Epoch [31/50], Step [900/938], Loss D: 1.3070, Loss G: 0.8466\n",
            "Epoch [32/50], Step [0/938], Loss D: 1.4528, Loss G: 0.7977\n",
            "Epoch [32/50], Step [100/938], Loss D: 1.3303, Loss G: 0.8176\n",
            "Epoch [32/50], Step [200/938], Loss D: 1.4226, Loss G: 0.8313\n",
            "Epoch [32/50], Step [300/938], Loss D: 1.3191, Loss G: 0.8314\n",
            "Epoch [32/50], Step [400/938], Loss D: 1.3582, Loss G: 0.8244\n",
            "Epoch [32/50], Step [500/938], Loss D: 1.3953, Loss G: 0.8088\n",
            "Epoch [32/50], Step [600/938], Loss D: 1.3440, Loss G: 0.8858\n",
            "Epoch [32/50], Step [700/938], Loss D: 1.3258, Loss G: 0.8770\n",
            "Epoch [32/50], Step [800/938], Loss D: 1.3159, Loss G: 0.8509\n",
            "Epoch [32/50], Step [900/938], Loss D: 1.3466, Loss G: 0.8487\n",
            "Epoch [33/50], Step [0/938], Loss D: 1.3288, Loss G: 0.8970\n",
            "Epoch [33/50], Step [100/938], Loss D: 1.3811, Loss G: 0.8268\n",
            "Epoch [33/50], Step [200/938], Loss D: 1.3132, Loss G: 0.8304\n",
            "Epoch [33/50], Step [300/938], Loss D: 1.3387, Loss G: 0.8474\n",
            "Epoch [33/50], Step [400/938], Loss D: 1.4043, Loss G: 0.7556\n",
            "Epoch [33/50], Step [500/938], Loss D: 1.3263, Loss G: 0.8606\n",
            "Epoch [33/50], Step [600/938], Loss D: 1.3300, Loss G: 0.8153\n",
            "Epoch [33/50], Step [700/938], Loss D: 1.2947, Loss G: 0.9045\n",
            "Epoch [33/50], Step [800/938], Loss D: 1.3164, Loss G: 0.8336\n",
            "Epoch [33/50], Step [900/938], Loss D: 1.3831, Loss G: 0.7802\n",
            "Epoch [34/50], Step [0/938], Loss D: 1.3306, Loss G: 0.8049\n",
            "Epoch [34/50], Step [100/938], Loss D: 1.3449, Loss G: 0.8267\n",
            "Epoch [34/50], Step [200/938], Loss D: 1.3689, Loss G: 0.8639\n",
            "Epoch [34/50], Step [300/938], Loss D: 1.3402, Loss G: 0.8471\n",
            "Epoch [34/50], Step [400/938], Loss D: 1.3724, Loss G: 0.7662\n",
            "Epoch [34/50], Step [500/938], Loss D: 1.2780, Loss G: 0.8455\n",
            "Epoch [34/50], Step [600/938], Loss D: 1.3973, Loss G: 0.8238\n",
            "Epoch [34/50], Step [700/938], Loss D: 1.4058, Loss G: 0.8145\n",
            "Epoch [34/50], Step [800/938], Loss D: 1.3466, Loss G: 0.8020\n",
            "Epoch [34/50], Step [900/938], Loss D: 1.3672, Loss G: 0.8151\n",
            "Epoch [35/50], Step [0/938], Loss D: 1.3945, Loss G: 0.7691\n",
            "Epoch [35/50], Step [100/938], Loss D: 1.3133, Loss G: 0.8198\n",
            "Epoch [35/50], Step [200/938], Loss D: 1.3993, Loss G: 0.8242\n",
            "Epoch [35/50], Step [300/938], Loss D: 1.3959, Loss G: 0.7751\n",
            "Epoch [35/50], Step [400/938], Loss D: 1.3829, Loss G: 0.7808\n",
            "Epoch [35/50], Step [500/938], Loss D: 1.3853, Loss G: 0.7741\n",
            "Epoch [35/50], Step [600/938], Loss D: 1.3699, Loss G: 0.8203\n",
            "Epoch [35/50], Step [700/938], Loss D: 1.3823, Loss G: 0.8588\n",
            "Epoch [35/50], Step [800/938], Loss D: 1.3239, Loss G: 0.8386\n",
            "Epoch [35/50], Step [900/938], Loss D: 1.3312, Loss G: 0.7998\n",
            "Epoch [36/50], Step [0/938], Loss D: 1.3675, Loss G: 0.8173\n",
            "Epoch [36/50], Step [100/938], Loss D: 1.3997, Loss G: 0.7673\n",
            "Epoch [36/50], Step [200/938], Loss D: 1.3406, Loss G: 0.8247\n",
            "Epoch [36/50], Step [300/938], Loss D: 1.3832, Loss G: 0.7576\n",
            "Epoch [36/50], Step [400/938], Loss D: 1.4333, Loss G: 0.8090\n",
            "Epoch [36/50], Step [500/938], Loss D: 1.3367, Loss G: 0.8044\n",
            "Epoch [36/50], Step [600/938], Loss D: 1.3746, Loss G: 0.7117\n",
            "Epoch [36/50], Step [700/938], Loss D: 1.2761, Loss G: 0.8111\n",
            "Epoch [36/50], Step [800/938], Loss D: 1.3763, Loss G: 0.7799\n",
            "Epoch [36/50], Step [900/938], Loss D: 1.4175, Loss G: 0.7842\n",
            "Epoch [37/50], Step [0/938], Loss D: 1.3681, Loss G: 0.8210\n",
            "Epoch [37/50], Step [100/938], Loss D: 1.3320, Loss G: 0.8214\n",
            "Epoch [37/50], Step [200/938], Loss D: 1.3990, Loss G: 0.7244\n",
            "Epoch [37/50], Step [300/938], Loss D: 1.3715, Loss G: 0.7660\n",
            "Epoch [37/50], Step [400/938], Loss D: 1.3318, Loss G: 0.8184\n",
            "Epoch [37/50], Step [500/938], Loss D: 1.3175, Loss G: 0.8538\n",
            "Epoch [37/50], Step [600/938], Loss D: 1.3610, Loss G: 0.7924\n",
            "Epoch [37/50], Step [700/938], Loss D: 1.3417, Loss G: 0.8031\n",
            "Epoch [37/50], Step [800/938], Loss D: 1.2986, Loss G: 0.8604\n",
            "Epoch [37/50], Step [900/938], Loss D: 1.3671, Loss G: 0.8582\n",
            "Epoch [38/50], Step [0/938], Loss D: 1.3822, Loss G: 0.7797\n",
            "Epoch [38/50], Step [100/938], Loss D: 1.3619, Loss G: 0.8472\n",
            "Epoch [38/50], Step [200/938], Loss D: 1.3334, Loss G: 0.8360\n",
            "Epoch [38/50], Step [300/938], Loss D: 1.3883, Loss G: 0.8058\n",
            "Epoch [38/50], Step [400/938], Loss D: 1.2990, Loss G: 0.8260\n",
            "Epoch [38/50], Step [500/938], Loss D: 1.3116, Loss G: 0.8030\n",
            "Epoch [38/50], Step [600/938], Loss D: 1.3755, Loss G: 0.7737\n",
            "Epoch [38/50], Step [700/938], Loss D: 1.3180, Loss G: 0.8446\n",
            "Epoch [38/50], Step [800/938], Loss D: 1.3722, Loss G: 0.8124\n",
            "Epoch [38/50], Step [900/938], Loss D: 1.3111, Loss G: 0.8248\n",
            "Epoch [39/50], Step [0/938], Loss D: 1.2893, Loss G: 0.8424\n",
            "Epoch [39/50], Step [100/938], Loss D: 1.3025, Loss G: 0.8680\n",
            "Epoch [39/50], Step [200/938], Loss D: 1.3759, Loss G: 0.8759\n",
            "Epoch [39/50], Step [300/938], Loss D: 1.3369, Loss G: 0.8089\n",
            "Epoch [39/50], Step [400/938], Loss D: 1.3003, Loss G: 0.9082\n",
            "Epoch [39/50], Step [500/938], Loss D: 1.3474, Loss G: 0.8091\n",
            "Epoch [39/50], Step [600/938], Loss D: 1.3516, Loss G: 0.8037\n",
            "Epoch [39/50], Step [700/938], Loss D: 1.3878, Loss G: 0.7833\n",
            "Epoch [39/50], Step [800/938], Loss D: 1.3384, Loss G: 0.8179\n",
            "Epoch [39/50], Step [900/938], Loss D: 1.3828, Loss G: 0.8679\n",
            "Epoch [40/50], Step [0/938], Loss D: 1.3408, Loss G: 0.7559\n",
            "Epoch [40/50], Step [100/938], Loss D: 1.4198, Loss G: 0.7727\n",
            "Epoch [40/50], Step [200/938], Loss D: 1.3976, Loss G: 0.7894\n",
            "Epoch [40/50], Step [300/938], Loss D: 1.3642, Loss G: 0.8836\n",
            "Epoch [40/50], Step [400/938], Loss D: 1.3576, Loss G: 0.7962\n",
            "Epoch [40/50], Step [500/938], Loss D: 1.3370, Loss G: 0.8162\n",
            "Epoch [40/50], Step [600/938], Loss D: 1.3338, Loss G: 0.8634\n",
            "Epoch [40/50], Step [700/938], Loss D: 1.3913, Loss G: 0.8093\n",
            "Epoch [40/50], Step [800/938], Loss D: 1.2595, Loss G: 0.8155\n",
            "Epoch [40/50], Step [900/938], Loss D: 1.3386, Loss G: 0.8267\n",
            "Epoch [41/50], Step [0/938], Loss D: 1.3293, Loss G: 0.8165\n",
            "Epoch [41/50], Step [100/938], Loss D: 1.3951, Loss G: 0.7737\n",
            "Epoch [41/50], Step [200/938], Loss D: 1.2897, Loss G: 0.8553\n",
            "Epoch [41/50], Step [300/938], Loss D: 1.4219, Loss G: 0.7942\n",
            "Epoch [41/50], Step [400/938], Loss D: 1.2952, Loss G: 0.8163\n",
            "Epoch [41/50], Step [500/938], Loss D: 1.3553, Loss G: 0.8095\n",
            "Epoch [41/50], Step [600/938], Loss D: 1.3054, Loss G: 0.8127\n",
            "Epoch [41/50], Step [700/938], Loss D: 1.3321, Loss G: 0.7959\n",
            "Epoch [41/50], Step [800/938], Loss D: 1.3196, Loss G: 0.8275\n",
            "Epoch [41/50], Step [900/938], Loss D: 1.2930, Loss G: 0.8623\n",
            "Epoch [42/50], Step [0/938], Loss D: 1.3176, Loss G: 0.8661\n",
            "Epoch [42/50], Step [100/938], Loss D: 1.3630, Loss G: 0.8716\n",
            "Epoch [42/50], Step [200/938], Loss D: 1.2967, Loss G: 0.8317\n",
            "Epoch [42/50], Step [300/938], Loss D: 1.3521, Loss G: 0.8548\n",
            "Epoch [42/50], Step [400/938], Loss D: 1.3086, Loss G: 0.8223\n",
            "Epoch [42/50], Step [500/938], Loss D: 1.3809, Loss G: 0.8337\n",
            "Epoch [42/50], Step [600/938], Loss D: 1.3992, Loss G: 0.7802\n",
            "Epoch [42/50], Step [700/938], Loss D: 1.3805, Loss G: 0.8453\n",
            "Epoch [42/50], Step [800/938], Loss D: 1.3159, Loss G: 0.8199\n",
            "Epoch [42/50], Step [900/938], Loss D: 1.3042, Loss G: 0.8342\n",
            "Epoch [43/50], Step [0/938], Loss D: 1.3112, Loss G: 0.8476\n",
            "Epoch [43/50], Step [100/938], Loss D: 1.3851, Loss G: 0.7685\n",
            "Epoch [43/50], Step [200/938], Loss D: 1.3733, Loss G: 0.8019\n",
            "Epoch [43/50], Step [300/938], Loss D: 1.3713, Loss G: 0.7994\n",
            "Epoch [43/50], Step [400/938], Loss D: 1.3135, Loss G: 0.8486\n",
            "Epoch [43/50], Step [500/938], Loss D: 1.3047, Loss G: 0.8338\n",
            "Epoch [43/50], Step [600/938], Loss D: 1.2900, Loss G: 0.8290\n",
            "Epoch [43/50], Step [700/938], Loss D: 1.3287, Loss G: 0.7861\n",
            "Epoch [43/50], Step [800/938], Loss D: 1.3769, Loss G: 0.8063\n",
            "Epoch [43/50], Step [900/938], Loss D: 1.3701, Loss G: 0.7804\n",
            "Epoch [44/50], Step [0/938], Loss D: 1.2957, Loss G: 0.8345\n",
            "Epoch [44/50], Step [100/938], Loss D: 1.3656, Loss G: 0.7554\n",
            "Epoch [44/50], Step [200/938], Loss D: 1.3573, Loss G: 0.8654\n",
            "Epoch [44/50], Step [300/938], Loss D: 1.3127, Loss G: 0.8360\n",
            "Epoch [44/50], Step [400/938], Loss D: 1.3634, Loss G: 0.8085\n",
            "Epoch [44/50], Step [500/938], Loss D: 1.3410, Loss G: 0.8263\n",
            "Epoch [44/50], Step [600/938], Loss D: 1.3225, Loss G: 0.8436\n",
            "Epoch [44/50], Step [700/938], Loss D: 1.3498, Loss G: 0.8009\n",
            "Epoch [44/50], Step [800/938], Loss D: 1.3121, Loss G: 0.8488\n",
            "Epoch [44/50], Step [900/938], Loss D: 1.3389, Loss G: 0.8832\n",
            "Epoch [45/50], Step [0/938], Loss D: 1.3011, Loss G: 0.8493\n",
            "Epoch [45/50], Step [100/938], Loss D: 1.3337, Loss G: 0.8689\n",
            "Epoch [45/50], Step [200/938], Loss D: 1.3751, Loss G: 0.8190\n",
            "Epoch [45/50], Step [300/938], Loss D: 1.3317, Loss G: 0.8090\n",
            "Epoch [45/50], Step [400/938], Loss D: 1.3571, Loss G: 0.8853\n",
            "Epoch [45/50], Step [500/938], Loss D: 1.3549, Loss G: 0.8814\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "z_dim = 100\n",
        "num_classes = 10\n",
        "image_size = 28 * 28  # Fashion MNIST image dimensions (28x28)\n",
        "lr = 0.0002\n",
        "epochs = 50\n",
        "\n",
        "# Create output directory for generated images\n",
        "os.makedirs('cgan_images', exist_ok=True)\n",
        "\n",
        "# Transformations for Fashion MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Conditional Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, img_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)  # Embedding for labels\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(z_dim + num_classes, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, img_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        # Concatenate latent vector and label embeddings\n",
        "        c = self.label_emb(labels)\n",
        "        x = torch.cat([z, c], dim=1)\n",
        "        return self.model(x).view(x.size(0), 1, 28, 28)\n",
        "\n",
        "# Conditional Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(img_dim + num_classes, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        # Concatenate image and label embeddings\n",
        "        c = self.label_emb(labels)\n",
        "        x = torch.cat([img.view(img.size(0), -1), c], dim=1)\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator(z_dim, num_classes, image_size).to(device)\n",
        "discriminator = Discriminator(num_classes, image_size).to(device)\n",
        "\n",
        "# Loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    for i, (real_images, labels) in enumerate(train_loader):\n",
        "        real_images, labels = real_images.to(device), labels.to(device)\n",
        "\n",
        "        # Labels for real and fake data\n",
        "        real_labels = torch.ones(real_images.size(0), 1).to(device)\n",
        "        fake_labels = torch.zeros(real_images.size(0), 1).to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        # Real images loss\n",
        "        real_outputs = discriminator(real_images, labels)\n",
        "        loss_real = criterion(real_outputs, real_labels)\n",
        "\n",
        "        # Generate fake images\n",
        "        z = torch.randn(real_images.size(0), z_dim).to(device)\n",
        "        fake_images = generator(z, labels)\n",
        "        fake_outputs = discriminator(fake_images.detach(), labels)\n",
        "        loss_fake = criterion(fake_outputs, fake_labels)\n",
        "\n",
        "        # Total loss and optimization\n",
        "        loss_d = loss_real + loss_fake\n",
        "        loss_d.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        # Generator loss (fool the discriminator)\n",
        "        fake_outputs = discriminator(fake_images, labels)\n",
        "        loss_g = criterion(fake_outputs, real_labels)\n",
        "\n",
        "        loss_g.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # Log progress\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(train_loader)}], \"\n",
        "                  f\"Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}\")\n",
        "\n",
        "    # Save generated images\n",
        "    z = torch.randn(100, z_dim).to(device)\n",
        "    sample_labels = torch.arange(0, num_classes).repeat(10).to(device)\n",
        "    sample_images = generator(z, sample_labels)\n",
        "    save_image(sample_images.data, f'cgan_images/epoch_{epoch}.png', nrow=10, normalize=True)\n",
        "\n",
        "# Display generated images after training\n",
        "sample_images = sample_images.data[:25].cpu()\n",
        "grid = save_image(sample_images, normalize=True, nrow=5)\n",
        "plt.imshow(grid.permute(1, 2, 0))\n",
        "plt.title(\"Generated Images\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ]
}