{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFLR-7dHKVeZ",
        "outputId": "374aeea1-ecb1-41f3-aa54-631c0a87fdab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 197kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.70MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 3.87MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Epoch [0/50], Step [0/938], Loss D: 1.3808, Loss G: 0.6960\n",
            "Epoch [0/50], Step [100/938], Loss D: 0.6613, Loss G: 1.0209\n",
            "Epoch [0/50], Step [200/938], Loss D: 0.8292, Loss G: 1.6267\n",
            "Epoch [0/50], Step [300/938], Loss D: 0.9192, Loss G: 2.7854\n",
            "Epoch [0/50], Step [400/938], Loss D: 0.8330, Loss G: 2.2322\n",
            "Epoch [0/50], Step [500/938], Loss D: 0.8113, Loss G: 1.6271\n",
            "Epoch [0/50], Step [600/938], Loss D: 0.5620, Loss G: 2.1931\n",
            "Epoch [0/50], Step [700/938], Loss D: 0.6324, Loss G: 2.5474\n",
            "Epoch [0/50], Step [800/938], Loss D: 0.5921, Loss G: 2.5117\n",
            "Epoch [0/50], Step [900/938], Loss D: 0.7939, Loss G: 3.2432\n",
            "Epoch [1/50], Step [0/938], Loss D: 0.5582, Loss G: 2.2503\n",
            "Epoch [1/50], Step [100/938], Loss D: 0.7078, Loss G: 1.9256\n",
            "Epoch [1/50], Step [200/938], Loss D: 1.0052, Loss G: 1.4955\n",
            "Epoch [1/50], Step [300/938], Loss D: 0.8113, Loss G: 1.6038\n",
            "Epoch [1/50], Step [400/938], Loss D: 1.0790, Loss G: 1.7969\n",
            "Epoch [1/50], Step [500/938], Loss D: 1.1573, Loss G: 1.7414\n",
            "Epoch [1/50], Step [600/938], Loss D: 1.1983, Loss G: 0.9821\n",
            "Epoch [1/50], Step [700/938], Loss D: 0.9772, Loss G: 1.5688\n",
            "Epoch [1/50], Step [800/938], Loss D: 0.9918, Loss G: 1.8996\n",
            "Epoch [1/50], Step [900/938], Loss D: 1.1480, Loss G: 1.5961\n",
            "Epoch [2/50], Step [0/938], Loss D: 1.2497, Loss G: 0.8728\n",
            "Epoch [2/50], Step [100/938], Loss D: 1.0596, Loss G: 1.7659\n",
            "Epoch [2/50], Step [200/938], Loss D: 1.0109, Loss G: 1.8388\n",
            "Epoch [2/50], Step [300/938], Loss D: 1.2074, Loss G: 1.2891\n",
            "Epoch [2/50], Step [400/938], Loss D: 1.2073, Loss G: 1.6368\n",
            "Epoch [2/50], Step [500/938], Loss D: 1.1453, Loss G: 1.8492\n",
            "Epoch [2/50], Step [600/938], Loss D: 1.0294, Loss G: 1.2884\n",
            "Epoch [2/50], Step [700/938], Loss D: 1.1415, Loss G: 0.9627\n",
            "Epoch [2/50], Step [800/938], Loss D: 1.1650, Loss G: 1.5063\n",
            "Epoch [2/50], Step [900/938], Loss D: 1.1203, Loss G: 1.4064\n",
            "Epoch [3/50], Step [0/938], Loss D: 1.1758, Loss G: 0.9147\n",
            "Epoch [3/50], Step [100/938], Loss D: 1.2211, Loss G: 0.9566\n",
            "Epoch [3/50], Step [200/938], Loss D: 1.1305, Loss G: 1.0794\n",
            "Epoch [3/50], Step [300/938], Loss D: 1.2466, Loss G: 1.0849\n",
            "Epoch [3/50], Step [400/938], Loss D: 1.2179, Loss G: 1.6660\n",
            "Epoch [3/50], Step [500/938], Loss D: 1.1996, Loss G: 1.3142\n",
            "Epoch [3/50], Step [600/938], Loss D: 1.1366, Loss G: 1.6333\n",
            "Epoch [3/50], Step [700/938], Loss D: 1.2889, Loss G: 1.0251\n",
            "Epoch [3/50], Step [800/938], Loss D: 1.3148, Loss G: 0.8708\n",
            "Epoch [3/50], Step [900/938], Loss D: 1.1288, Loss G: 1.0290\n",
            "Epoch [4/50], Step [0/938], Loss D: 1.3099, Loss G: 0.9013\n",
            "Epoch [4/50], Step [100/938], Loss D: 1.1753, Loss G: 1.1499\n",
            "Epoch [4/50], Step [200/938], Loss D: 1.1969, Loss G: 1.0319\n",
            "Epoch [4/50], Step [300/938], Loss D: 1.2521, Loss G: 1.2700\n",
            "Epoch [4/50], Step [400/938], Loss D: 1.2101, Loss G: 1.2561\n",
            "Epoch [4/50], Step [500/938], Loss D: 1.2129, Loss G: 1.2733\n",
            "Epoch [4/50], Step [600/938], Loss D: 1.3326, Loss G: 1.0602\n",
            "Epoch [4/50], Step [700/938], Loss D: 1.2346, Loss G: 1.2652\n",
            "Epoch [4/50], Step [800/938], Loss D: 1.1954, Loss G: 1.2136\n",
            "Epoch [4/50], Step [900/938], Loss D: 1.2484, Loss G: 1.0878\n",
            "Epoch [5/50], Step [0/938], Loss D: 1.2197, Loss G: 1.1453\n",
            "Epoch [5/50], Step [100/938], Loss D: 1.2397, Loss G: 1.0734\n",
            "Epoch [5/50], Step [200/938], Loss D: 1.1922, Loss G: 1.1279\n",
            "Epoch [5/50], Step [300/938], Loss D: 1.2342, Loss G: 0.7872\n",
            "Epoch [5/50], Step [400/938], Loss D: 1.1638, Loss G: 1.2116\n",
            "Epoch [5/50], Step [500/938], Loss D: 1.3076, Loss G: 0.9191\n",
            "Epoch [5/50], Step [600/938], Loss D: 1.2617, Loss G: 1.1208\n",
            "Epoch [5/50], Step [700/938], Loss D: 1.3463, Loss G: 0.8296\n",
            "Epoch [5/50], Step [800/938], Loss D: 1.2776, Loss G: 0.9017\n",
            "Epoch [5/50], Step [900/938], Loss D: 1.2645, Loss G: 0.8831\n",
            "Epoch [6/50], Step [0/938], Loss D: 1.3382, Loss G: 1.0958\n",
            "Epoch [6/50], Step [100/938], Loss D: 1.2095, Loss G: 1.0613\n",
            "Epoch [6/50], Step [200/938], Loss D: 1.3854, Loss G: 0.8186\n",
            "Epoch [6/50], Step [300/938], Loss D: 1.3427, Loss G: 1.0907\n",
            "Epoch [6/50], Step [400/938], Loss D: 1.2888, Loss G: 0.7812\n",
            "Epoch [6/50], Step [500/938], Loss D: 1.3933, Loss G: 0.8288\n",
            "Epoch [6/50], Step [600/938], Loss D: 1.2476, Loss G: 0.8620\n",
            "Epoch [6/50], Step [700/938], Loss D: 1.3927, Loss G: 1.1572\n",
            "Epoch [6/50], Step [800/938], Loss D: 1.2997, Loss G: 0.8822\n",
            "Epoch [6/50], Step [900/938], Loss D: 1.2268, Loss G: 0.8822\n",
            "Epoch [7/50], Step [0/938], Loss D: 1.4157, Loss G: 1.2294\n",
            "Epoch [7/50], Step [100/938], Loss D: 1.3228, Loss G: 1.0708\n",
            "Epoch [7/50], Step [200/938], Loss D: 1.2764, Loss G: 0.9699\n",
            "Epoch [7/50], Step [300/938], Loss D: 1.2955, Loss G: 0.9041\n",
            "Epoch [7/50], Step [400/938], Loss D: 1.1732, Loss G: 0.9965\n",
            "Epoch [7/50], Step [500/938], Loss D: 1.2888, Loss G: 0.9850\n",
            "Epoch [7/50], Step [600/938], Loss D: 1.2074, Loss G: 1.0082\n",
            "Epoch [7/50], Step [700/938], Loss D: 1.3628, Loss G: 0.7872\n",
            "Epoch [7/50], Step [800/938], Loss D: 1.3012, Loss G: 1.0242\n",
            "Epoch [7/50], Step [900/938], Loss D: 1.2648, Loss G: 0.8372\n",
            "Epoch [8/50], Step [0/938], Loss D: 1.3169, Loss G: 1.0095\n",
            "Epoch [8/50], Step [100/938], Loss D: 1.2050, Loss G: 0.9588\n",
            "Epoch [8/50], Step [200/938], Loss D: 1.3383, Loss G: 0.9214\n",
            "Epoch [8/50], Step [300/938], Loss D: 1.2990, Loss G: 1.0047\n",
            "Epoch [8/50], Step [400/938], Loss D: 1.3483, Loss G: 0.9550\n",
            "Epoch [8/50], Step [500/938], Loss D: 1.4295, Loss G: 1.0124\n",
            "Epoch [8/50], Step [600/938], Loss D: 1.2685, Loss G: 0.9744\n",
            "Epoch [8/50], Step [700/938], Loss D: 1.4206, Loss G: 0.8667\n",
            "Epoch [8/50], Step [800/938], Loss D: 1.2856, Loss G: 1.0472\n",
            "Epoch [8/50], Step [900/938], Loss D: 1.2693, Loss G: 0.9152\n",
            "Epoch [9/50], Step [0/938], Loss D: 1.2707, Loss G: 0.8796\n",
            "Epoch [9/50], Step [100/938], Loss D: 1.2249, Loss G: 0.8989\n",
            "Epoch [9/50], Step [200/938], Loss D: 1.2562, Loss G: 0.7093\n",
            "Epoch [9/50], Step [300/938], Loss D: 1.3590, Loss G: 0.7802\n",
            "Epoch [9/50], Step [400/938], Loss D: 1.2919, Loss G: 0.9002\n",
            "Epoch [9/50], Step [500/938], Loss D: 1.4201, Loss G: 0.9310\n",
            "Epoch [9/50], Step [600/938], Loss D: 1.2697, Loss G: 0.9902\n",
            "Epoch [9/50], Step [700/938], Loss D: 1.2979, Loss G: 0.8531\n",
            "Epoch [9/50], Step [800/938], Loss D: 1.2210, Loss G: 0.9103\n",
            "Epoch [9/50], Step [900/938], Loss D: 1.3321, Loss G: 0.8224\n",
            "Epoch [10/50], Step [0/938], Loss D: 1.2479, Loss G: 1.1835\n",
            "Epoch [10/50], Step [100/938], Loss D: 1.2490, Loss G: 0.9514\n",
            "Epoch [10/50], Step [200/938], Loss D: 1.2885, Loss G: 1.1126\n",
            "Epoch [10/50], Step [300/938], Loss D: 1.3597, Loss G: 0.7846\n",
            "Epoch [10/50], Step [400/938], Loss D: 1.2670, Loss G: 0.9953\n",
            "Epoch [10/50], Step [500/938], Loss D: 1.2561, Loss G: 0.9045\n",
            "Epoch [10/50], Step [600/938], Loss D: 1.2028, Loss G: 0.9926\n",
            "Epoch [10/50], Step [700/938], Loss D: 1.2598, Loss G: 0.9454\n",
            "Epoch [10/50], Step [800/938], Loss D: 1.3062, Loss G: 0.8090\n",
            "Epoch [10/50], Step [900/938], Loss D: 1.3508, Loss G: 0.7578\n",
            "Epoch [11/50], Step [0/938], Loss D: 1.3147, Loss G: 0.8163\n",
            "Epoch [11/50], Step [100/938], Loss D: 1.2944, Loss G: 0.8011\n",
            "Epoch [11/50], Step [200/938], Loss D: 1.3732, Loss G: 0.8653\n",
            "Epoch [11/50], Step [300/938], Loss D: 1.3028, Loss G: 0.8907\n",
            "Epoch [11/50], Step [400/938], Loss D: 1.3203, Loss G: 0.9066\n",
            "Epoch [11/50], Step [500/938], Loss D: 1.2250, Loss G: 0.9785\n",
            "Epoch [11/50], Step [600/938], Loss D: 1.3695, Loss G: 0.8826\n",
            "Epoch [11/50], Step [700/938], Loss D: 1.3349, Loss G: 0.8507\n",
            "Epoch [11/50], Step [800/938], Loss D: 1.2684, Loss G: 0.8437\n",
            "Epoch [11/50], Step [900/938], Loss D: 1.3351, Loss G: 0.9299\n",
            "Epoch [12/50], Step [0/938], Loss D: 1.3540, Loss G: 0.7755\n",
            "Epoch [12/50], Step [100/938], Loss D: 1.3325, Loss G: 0.8220\n",
            "Epoch [12/50], Step [200/938], Loss D: 1.3924, Loss G: 0.7049\n",
            "Epoch [12/50], Step [300/938], Loss D: 1.3463, Loss G: 0.9662\n",
            "Epoch [12/50], Step [400/938], Loss D: 1.4396, Loss G: 0.9773\n",
            "Epoch [12/50], Step [500/938], Loss D: 1.2577, Loss G: 0.9181\n",
            "Epoch [12/50], Step [600/938], Loss D: 1.3128, Loss G: 0.8913\n",
            "Epoch [12/50], Step [700/938], Loss D: 1.3455, Loss G: 1.1984\n",
            "Epoch [12/50], Step [800/938], Loss D: 1.3167, Loss G: 0.7571\n",
            "Epoch [12/50], Step [900/938], Loss D: 1.3606, Loss G: 0.8370\n",
            "Epoch [13/50], Step [0/938], Loss D: 1.3250, Loss G: 0.8419\n",
            "Epoch [13/50], Step [100/938], Loss D: 1.2704, Loss G: 1.0160\n",
            "Epoch [13/50], Step [200/938], Loss D: 1.3646, Loss G: 0.9817\n",
            "Epoch [13/50], Step [300/938], Loss D: 1.2190, Loss G: 0.8776\n",
            "Epoch [13/50], Step [400/938], Loss D: 1.2894, Loss G: 0.9640\n",
            "Epoch [13/50], Step [500/938], Loss D: 1.3121, Loss G: 0.8231\n",
            "Epoch [13/50], Step [600/938], Loss D: 1.3338, Loss G: 0.8419\n",
            "Epoch [13/50], Step [700/938], Loss D: 1.2723, Loss G: 0.8509\n",
            "Epoch [13/50], Step [800/938], Loss D: 1.3904, Loss G: 0.8093\n",
            "Epoch [13/50], Step [900/938], Loss D: 1.3284, Loss G: 0.7918\n",
            "Epoch [14/50], Step [0/938], Loss D: 1.3225, Loss G: 0.8820\n",
            "Epoch [14/50], Step [100/938], Loss D: 1.2777, Loss G: 0.9000\n",
            "Epoch [14/50], Step [200/938], Loss D: 1.3761, Loss G: 0.8693\n",
            "Epoch [14/50], Step [300/938], Loss D: 1.2721, Loss G: 0.8704\n",
            "Epoch [14/50], Step [400/938], Loss D: 1.3140, Loss G: 0.9064\n",
            "Epoch [14/50], Step [500/938], Loss D: 1.3271, Loss G: 0.9109\n",
            "Epoch [14/50], Step [600/938], Loss D: 1.3886, Loss G: 0.9087\n",
            "Epoch [14/50], Step [700/938], Loss D: 1.3624, Loss G: 0.8725\n",
            "Epoch [14/50], Step [800/938], Loss D: 1.3528, Loss G: 0.9197\n",
            "Epoch [14/50], Step [900/938], Loss D: 1.3060, Loss G: 0.9327\n",
            "Epoch [15/50], Step [0/938], Loss D: 1.3914, Loss G: 0.7618\n",
            "Epoch [15/50], Step [100/938], Loss D: 1.2664, Loss G: 0.9397\n",
            "Epoch [15/50], Step [200/938], Loss D: 1.3070, Loss G: 0.8897\n",
            "Epoch [15/50], Step [300/938], Loss D: 1.3108, Loss G: 0.8985\n",
            "Epoch [15/50], Step [400/938], Loss D: 1.3538, Loss G: 0.9617\n",
            "Epoch [15/50], Step [500/938], Loss D: 1.3588, Loss G: 0.7808\n",
            "Epoch [15/50], Step [600/938], Loss D: 1.3227, Loss G: 0.9366\n",
            "Epoch [15/50], Step [700/938], Loss D: 1.2992, Loss G: 0.8044\n",
            "Epoch [15/50], Step [800/938], Loss D: 1.3402, Loss G: 0.7880\n",
            "Epoch [15/50], Step [900/938], Loss D: 1.2895, Loss G: 0.9517\n",
            "Epoch [16/50], Step [0/938], Loss D: 1.2724, Loss G: 0.9902\n",
            "Epoch [16/50], Step [100/938], Loss D: 1.2851, Loss G: 0.8780\n",
            "Epoch [16/50], Step [200/938], Loss D: 1.2920, Loss G: 0.9522\n",
            "Epoch [16/50], Step [300/938], Loss D: 1.2924, Loss G: 0.9482\n",
            "Epoch [16/50], Step [400/938], Loss D: 1.2454, Loss G: 0.9683\n",
            "Epoch [16/50], Step [500/938], Loss D: 1.3438, Loss G: 0.8868\n",
            "Epoch [16/50], Step [600/938], Loss D: 1.3877, Loss G: 0.8934\n",
            "Epoch [16/50], Step [700/938], Loss D: 1.2352, Loss G: 0.8808\n",
            "Epoch [16/50], Step [800/938], Loss D: 1.3663, Loss G: 0.9529\n",
            "Epoch [16/50], Step [900/938], Loss D: 1.3633, Loss G: 0.9086\n",
            "Epoch [17/50], Step [0/938], Loss D: 1.3540, Loss G: 0.8238\n",
            "Epoch [17/50], Step [100/938], Loss D: 1.2742, Loss G: 0.8560\n",
            "Epoch [17/50], Step [200/938], Loss D: 1.4318, Loss G: 0.7505\n",
            "Epoch [17/50], Step [300/938], Loss D: 1.4030, Loss G: 0.8714\n",
            "Epoch [17/50], Step [400/938], Loss D: 1.3399, Loss G: 0.8379\n",
            "Epoch [17/50], Step [500/938], Loss D: 1.3277, Loss G: 0.8835\n",
            "Epoch [17/50], Step [600/938], Loss D: 1.3396, Loss G: 0.8060\n",
            "Epoch [17/50], Step [700/938], Loss D: 1.3937, Loss G: 0.8771\n",
            "Epoch [17/50], Step [800/938], Loss D: 1.4142, Loss G: 0.7974\n",
            "Epoch [17/50], Step [900/938], Loss D: 1.3379, Loss G: 0.8909\n",
            "Epoch [18/50], Step [0/938], Loss D: 1.3504, Loss G: 0.8375\n",
            "Epoch [18/50], Step [100/938], Loss D: 1.3739, Loss G: 0.8007\n",
            "Epoch [18/50], Step [200/938], Loss D: 1.3097, Loss G: 0.9119\n",
            "Epoch [18/50], Step [300/938], Loss D: 1.3187, Loss G: 0.8356\n",
            "Epoch [18/50], Step [400/938], Loss D: 1.3778, Loss G: 0.8210\n",
            "Epoch [18/50], Step [500/938], Loss D: 1.3132, Loss G: 0.8449\n",
            "Epoch [18/50], Step [600/938], Loss D: 1.3873, Loss G: 0.8891\n",
            "Epoch [18/50], Step [700/938], Loss D: 1.2790, Loss G: 0.9561\n",
            "Epoch [18/50], Step [800/938], Loss D: 1.3137, Loss G: 0.9705\n",
            "Epoch [18/50], Step [900/938], Loss D: 1.3388, Loss G: 0.8143\n",
            "Epoch [19/50], Step [0/938], Loss D: 1.3144, Loss G: 0.8462\n",
            "Epoch [19/50], Step [100/938], Loss D: 1.3119, Loss G: 0.8543\n",
            "Epoch [19/50], Step [200/938], Loss D: 1.3716, Loss G: 0.9096\n",
            "Epoch [19/50], Step [300/938], Loss D: 1.2838, Loss G: 0.8858\n",
            "Epoch [19/50], Step [400/938], Loss D: 1.3088, Loss G: 0.9519\n",
            "Epoch [19/50], Step [500/938], Loss D: 1.3125, Loss G: 0.8699\n",
            "Epoch [19/50], Step [600/938], Loss D: 1.4126, Loss G: 0.7713\n",
            "Epoch [19/50], Step [700/938], Loss D: 1.2980, Loss G: 0.9224\n",
            "Epoch [19/50], Step [800/938], Loss D: 1.3136, Loss G: 0.9207\n",
            "Epoch [19/50], Step [900/938], Loss D: 1.4121, Loss G: 0.8059\n",
            "Epoch [20/50], Step [0/938], Loss D: 1.4112, Loss G: 0.8319\n",
            "Epoch [20/50], Step [100/938], Loss D: 1.3225, Loss G: 0.8541\n",
            "Epoch [20/50], Step [200/938], Loss D: 1.3174, Loss G: 0.7777\n",
            "Epoch [20/50], Step [300/938], Loss D: 1.3804, Loss G: 0.8807\n",
            "Epoch [20/50], Step [400/938], Loss D: 1.3719, Loss G: 0.8097\n",
            "Epoch [20/50], Step [500/938], Loss D: 1.4092, Loss G: 0.8448\n",
            "Epoch [20/50], Step [600/938], Loss D: 1.3549, Loss G: 0.9356\n",
            "Epoch [20/50], Step [700/938], Loss D: 1.3333, Loss G: 0.8184\n",
            "Epoch [20/50], Step [800/938], Loss D: 1.2999, Loss G: 0.7987\n",
            "Epoch [20/50], Step [900/938], Loss D: 1.3351, Loss G: 0.8879\n",
            "Epoch [21/50], Step [0/938], Loss D: 1.3372, Loss G: 0.7893\n",
            "Epoch [21/50], Step [100/938], Loss D: 1.3217, Loss G: 0.8185\n",
            "Epoch [21/50], Step [200/938], Loss D: 1.3743, Loss G: 0.7845\n",
            "Epoch [21/50], Step [300/938], Loss D: 1.3689, Loss G: 0.8283\n",
            "Epoch [21/50], Step [400/938], Loss D: 1.4010, Loss G: 0.7778\n",
            "Epoch [21/50], Step [500/938], Loss D: 1.3806, Loss G: 0.7884\n",
            "Epoch [21/50], Step [600/938], Loss D: 1.3095, Loss G: 0.8867\n",
            "Epoch [21/50], Step [700/938], Loss D: 1.3641, Loss G: 0.7367\n",
            "Epoch [21/50], Step [800/938], Loss D: 1.3489, Loss G: 0.8333\n",
            "Epoch [21/50], Step [900/938], Loss D: 1.3448, Loss G: 0.8688\n",
            "Epoch [22/50], Step [0/938], Loss D: 1.3075, Loss G: 0.8160\n",
            "Epoch [22/50], Step [100/938], Loss D: 1.3429, Loss G: 0.7972\n",
            "Epoch [22/50], Step [200/938], Loss D: 1.3721, Loss G: 0.7860\n",
            "Epoch [22/50], Step [300/938], Loss D: 1.3593, Loss G: 0.8294\n",
            "Epoch [22/50], Step [400/938], Loss D: 1.3543, Loss G: 0.8090\n",
            "Epoch [22/50], Step [500/938], Loss D: 1.2952, Loss G: 0.8268\n",
            "Epoch [22/50], Step [600/938], Loss D: 1.2985, Loss G: 0.8258\n",
            "Epoch [22/50], Step [700/938], Loss D: 1.3684, Loss G: 0.7799\n",
            "Epoch [22/50], Step [800/938], Loss D: 1.3115, Loss G: 0.9024\n",
            "Epoch [22/50], Step [900/938], Loss D: 1.3199, Loss G: 0.7952\n",
            "Epoch [23/50], Step [0/938], Loss D: 1.4117, Loss G: 0.7771\n",
            "Epoch [23/50], Step [100/938], Loss D: 1.3109, Loss G: 0.8241\n",
            "Epoch [23/50], Step [200/938], Loss D: 1.3249, Loss G: 0.9431\n",
            "Epoch [23/50], Step [300/938], Loss D: 1.3170, Loss G: 0.8477\n",
            "Epoch [23/50], Step [400/938], Loss D: 1.4448, Loss G: 0.8041\n",
            "Epoch [23/50], Step [500/938], Loss D: 1.3634, Loss G: 0.8575\n",
            "Epoch [23/50], Step [600/938], Loss D: 1.3297, Loss G: 0.8799\n",
            "Epoch [23/50], Step [700/938], Loss D: 1.4036, Loss G: 0.7369\n",
            "Epoch [23/50], Step [800/938], Loss D: 1.2951, Loss G: 0.8050\n",
            "Epoch [23/50], Step [900/938], Loss D: 1.3342, Loss G: 0.7819\n",
            "Epoch [24/50], Step [0/938], Loss D: 1.2976, Loss G: 0.8324\n",
            "Epoch [24/50], Step [100/938], Loss D: 1.3029, Loss G: 0.8353\n",
            "Epoch [24/50], Step [200/938], Loss D: 1.4364, Loss G: 0.8671\n",
            "Epoch [24/50], Step [300/938], Loss D: 1.3022, Loss G: 0.8518\n",
            "Epoch [24/50], Step [400/938], Loss D: 1.3145, Loss G: 0.8217\n",
            "Epoch [24/50], Step [500/938], Loss D: 1.3605, Loss G: 0.7860\n",
            "Epoch [24/50], Step [600/938], Loss D: 1.3585, Loss G: 0.7557\n",
            "Epoch [24/50], Step [700/938], Loss D: 1.3836, Loss G: 0.8356\n",
            "Epoch [24/50], Step [800/938], Loss D: 1.2642, Loss G: 0.8817\n",
            "Epoch [24/50], Step [900/938], Loss D: 1.3521, Loss G: 0.8305\n",
            "Epoch [25/50], Step [0/938], Loss D: 1.4077, Loss G: 0.7675\n",
            "Epoch [25/50], Step [100/938], Loss D: 1.3345, Loss G: 0.7964\n",
            "Epoch [25/50], Step [200/938], Loss D: 1.2886, Loss G: 0.8441\n",
            "Epoch [25/50], Step [300/938], Loss D: 1.4479, Loss G: 0.7557\n",
            "Epoch [25/50], Step [400/938], Loss D: 1.3404, Loss G: 0.8020\n",
            "Epoch [25/50], Step [500/938], Loss D: 1.3956, Loss G: 0.8149\n",
            "Epoch [25/50], Step [600/938], Loss D: 1.2945, Loss G: 0.8776\n",
            "Epoch [25/50], Step [700/938], Loss D: 1.3139, Loss G: 0.8599\n",
            "Epoch [25/50], Step [800/938], Loss D: 1.3229, Loss G: 0.8549\n",
            "Epoch [25/50], Step [900/938], Loss D: 1.3949, Loss G: 0.8605\n",
            "Epoch [26/50], Step [0/938], Loss D: 1.4128, Loss G: 0.8473\n",
            "Epoch [26/50], Step [100/938], Loss D: 1.3216, Loss G: 0.9029\n",
            "Epoch [26/50], Step [200/938], Loss D: 1.3059, Loss G: 0.8453\n",
            "Epoch [26/50], Step [300/938], Loss D: 1.3174, Loss G: 0.7799\n",
            "Epoch [26/50], Step [400/938], Loss D: 1.3611, Loss G: 0.8628\n",
            "Epoch [26/50], Step [500/938], Loss D: 1.2922, Loss G: 0.8360\n",
            "Epoch [26/50], Step [600/938], Loss D: 1.3816, Loss G: 0.7708\n",
            "Epoch [26/50], Step [700/938], Loss D: 1.3239, Loss G: 0.8543\n",
            "Epoch [26/50], Step [800/938], Loss D: 1.3231, Loss G: 0.8035\n",
            "Epoch [26/50], Step [900/938], Loss D: 1.3098, Loss G: 0.8491\n",
            "Epoch [27/50], Step [0/938], Loss D: 1.3110, Loss G: 0.8206\n",
            "Epoch [27/50], Step [100/938], Loss D: 1.4250, Loss G: 0.8419\n",
            "Epoch [27/50], Step [200/938], Loss D: 1.3703, Loss G: 0.7624\n",
            "Epoch [27/50], Step [300/938], Loss D: 1.3653, Loss G: 0.8294\n",
            "Epoch [27/50], Step [400/938], Loss D: 1.3576, Loss G: 0.8033\n",
            "Epoch [27/50], Step [500/938], Loss D: 1.3341, Loss G: 0.8393\n",
            "Epoch [27/50], Step [600/938], Loss D: 1.3265, Loss G: 0.8982\n",
            "Epoch [27/50], Step [700/938], Loss D: 1.3138, Loss G: 0.8455\n",
            "Epoch [27/50], Step [800/938], Loss D: 1.4028, Loss G: 0.7940\n",
            "Epoch [27/50], Step [900/938], Loss D: 1.3283, Loss G: 0.8086\n",
            "Epoch [28/50], Step [0/938], Loss D: 1.3189, Loss G: 0.7944\n",
            "Epoch [28/50], Step [100/938], Loss D: 1.3510, Loss G: 0.8669\n",
            "Epoch [28/50], Step [200/938], Loss D: 1.4347, Loss G: 0.8212\n",
            "Epoch [28/50], Step [300/938], Loss D: 1.4088, Loss G: 0.7729\n",
            "Epoch [28/50], Step [400/938], Loss D: 1.3868, Loss G: 0.8432\n",
            "Epoch [28/50], Step [500/938], Loss D: 1.2989, Loss G: 0.8493\n",
            "Epoch [28/50], Step [600/938], Loss D: 1.4134, Loss G: 0.7634\n",
            "Epoch [28/50], Step [700/938], Loss D: 1.2943, Loss G: 0.8091\n",
            "Epoch [28/50], Step [800/938], Loss D: 1.2864, Loss G: 0.8298\n",
            "Epoch [28/50], Step [900/938], Loss D: 1.3354, Loss G: 0.8446\n",
            "Epoch [29/50], Step [0/938], Loss D: 1.3138, Loss G: 0.8202\n",
            "Epoch [29/50], Step [100/938], Loss D: 1.3237, Loss G: 0.8406\n",
            "Epoch [29/50], Step [200/938], Loss D: 1.3254, Loss G: 0.8089\n",
            "Epoch [29/50], Step [300/938], Loss D: 1.3651, Loss G: 0.7989\n",
            "Epoch [29/50], Step [400/938], Loss D: 1.3565, Loss G: 0.8072\n",
            "Epoch [29/50], Step [500/938], Loss D: 1.3598, Loss G: 0.8508\n",
            "Epoch [29/50], Step [600/938], Loss D: 1.3309, Loss G: 0.7970\n",
            "Epoch [29/50], Step [700/938], Loss D: 1.3053, Loss G: 0.8414\n",
            "Epoch [29/50], Step [800/938], Loss D: 1.3125, Loss G: 0.9030\n",
            "Epoch [29/50], Step [900/938], Loss D: 1.4153, Loss G: 0.7976\n",
            "Epoch [30/50], Step [0/938], Loss D: 1.3716, Loss G: 0.7927\n",
            "Epoch [30/50], Step [100/938], Loss D: 1.3397, Loss G: 0.8245\n",
            "Epoch [30/50], Step [200/938], Loss D: 1.3220, Loss G: 0.7908\n",
            "Epoch [30/50], Step [300/938], Loss D: 1.3593, Loss G: 0.7626\n",
            "Epoch [30/50], Step [400/938], Loss D: 1.3025, Loss G: 0.8716\n",
            "Epoch [30/50], Step [500/938], Loss D: 1.3516, Loss G: 0.8042\n",
            "Epoch [30/50], Step [600/938], Loss D: 1.3208, Loss G: 0.8793\n",
            "Epoch [30/50], Step [700/938], Loss D: 1.3755, Loss G: 0.7861\n",
            "Epoch [30/50], Step [800/938], Loss D: 1.3140, Loss G: 0.7859\n",
            "Epoch [30/50], Step [900/938], Loss D: 1.3427, Loss G: 0.8506\n",
            "Epoch [31/50], Step [0/938], Loss D: 1.3105, Loss G: 0.7918\n",
            "Epoch [31/50], Step [100/938], Loss D: 1.2765, Loss G: 0.8831\n",
            "Epoch [31/50], Step [200/938], Loss D: 1.3339, Loss G: 0.8639\n",
            "Epoch [31/50], Step [300/938], Loss D: 1.3769, Loss G: 0.7689\n",
            "Epoch [31/50], Step [400/938], Loss D: 1.2697, Loss G: 0.8475\n",
            "Epoch [31/50], Step [500/938], Loss D: 1.3670, Loss G: 0.8054\n",
            "Epoch [31/50], Step [600/938], Loss D: 1.3438, Loss G: 0.7692\n",
            "Epoch [31/50], Step [700/938], Loss D: 1.2604, Loss G: 0.8632\n",
            "Epoch [31/50], Step [800/938], Loss D: 1.2937, Loss G: 0.8621\n",
            "Epoch [31/50], Step [900/938], Loss D: 1.3951, Loss G: 0.8331\n",
            "Epoch [32/50], Step [0/938], Loss D: 1.3388, Loss G: 0.8322\n",
            "Epoch [32/50], Step [100/938], Loss D: 1.3012, Loss G: 0.8728\n",
            "Epoch [32/50], Step [200/938], Loss D: 1.3602, Loss G: 0.8479\n",
            "Epoch [32/50], Step [300/938], Loss D: 1.3576, Loss G: 0.8411\n",
            "Epoch [32/50], Step [400/938], Loss D: 1.3968, Loss G: 0.9054\n",
            "Epoch [32/50], Step [500/938], Loss D: 1.3981, Loss G: 0.8199\n",
            "Epoch [32/50], Step [600/938], Loss D: 1.3046, Loss G: 0.8353\n",
            "Epoch [32/50], Step [700/938], Loss D: 1.3160, Loss G: 0.8333\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "z_dim = 100\n",
        "num_classes = 10\n",
        "image_size = 28 * 28  # Fashion MNIST image dimensions (28x28)\n",
        "lr = 0.0002\n",
        "epochs = 50\n",
        "\n",
        "# Create output directory for generated images\n",
        "os.makedirs('cgan_images', exist_ok=True)\n",
        "\n",
        "# Transformations for Fashion MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Conditional Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, img_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)  # Embedding for labels\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(z_dim + num_classes, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, img_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        # Concatenate latent vector and label embeddings\n",
        "        c = self.label_emb(labels)\n",
        "        x = torch.cat([z, c], dim=1)\n",
        "        return self.model(x).view(x.size(0), 1, 28, 28)\n",
        "\n",
        "# Conditional Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(img_dim + num_classes, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        # Concatenate image and label embeddings\n",
        "        c = self.label_emb(labels)\n",
        "        x = torch.cat([img.view(img.size(0), -1), c], dim=1)\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator(z_dim, num_classes, image_size).to(device)\n",
        "discriminator = Discriminator(num_classes, image_size).to(device)\n",
        "\n",
        "# Loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    for i, (real_images, labels) in enumerate(train_loader):\n",
        "        real_images, labels = real_images.to(device), labels.to(device)\n",
        "\n",
        "        # Labels for real and fake data\n",
        "        real_labels = torch.ones(real_images.size(0), 1).to(device)\n",
        "        fake_labels = torch.zeros(real_images.size(0), 1).to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        # Real images loss\n",
        "        real_outputs = discriminator(real_images, labels)\n",
        "        loss_real = criterion(real_outputs, real_labels)\n",
        "\n",
        "        # Generate fake images\n",
        "        z = torch.randn(real_images.size(0), z_dim).to(device)\n",
        "        fake_images = generator(z, labels)\n",
        "        fake_outputs = discriminator(fake_images.detach(), labels)\n",
        "        loss_fake = criterion(fake_outputs, fake_labels)\n",
        "\n",
        "        # Total loss and optimization\n",
        "        loss_d = loss_real + loss_fake\n",
        "        loss_d.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        # Generator loss (fool the discriminator)\n",
        "        fake_outputs = discriminator(fake_images, labels)\n",
        "        loss_g = criterion(fake_outputs, real_labels)\n",
        "\n",
        "        loss_g.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # Log progress\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(train_loader)}], \"\n",
        "                  f\"Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}\")\n",
        "\n",
        "    # Save generated images\n",
        "    z = torch.randn(100, z_dim).to(device)\n",
        "    sample_labels = torch.arange(0, num_classes).repeat(10).to(device)\n",
        "    sample_images = generator(z, sample_labels)\n",
        "    save_image(sample_images.data, f'cgan_images/epoch_{epoch}.png', nrow=10, normalize=True)\n",
        "\n",
        "# Display generated images after training\n",
        "sample_images = sample_images.data[:25].cpu()\n",
        "grid = save_image(sample_images, normalize=True, nrow=5)\n",
        "plt.imshow(grid.permute(1, 2, 0))\n",
        "plt.title(\"Generated Images\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ]
}